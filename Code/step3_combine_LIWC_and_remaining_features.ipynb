{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"step3_combine_LIWC_and_remaining_features.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbHITS4dAYPdMsP5EcJhFp"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xCM8BvFZGA7j"},"source":["author: \"Anu Shrestha\"\n","\n","# Combining all features including LIWC features\n","This file contains the code that merge psychological features from LIWC tool with all remaining (complexity, stylistic and  emotion features) features used in paper.\n"]},{"cell_type":"code","metadata":{"id":"aELmH_OPU-va","executionInfo":{"status":"ok","timestamp":1604111784535,"user_tz":360,"elapsed":28880,"user":{"displayName":"Anu Shrestha","photoUrl":"","userId":"15243898305987665146"}},"outputId":"f53af9c0-eec0-445e-905f-e5b3ed812708","colab":{"base_uri":"https://localhost:8080/"}},"source":["\n","import nltk\n","nltk.download(\"punkt\")\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","stops = stopwords.words('english')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.tag import pos_tag\n","from nltk.tokenize import RegexpTokenizer\n","from nltk import sent_tokenize\n","import re, os\n","\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","import string\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ykhRedKqV1i-","executionInfo":{"status":"ok","timestamp":1604112001810,"user_tz":360,"elapsed":1255,"user":{"displayName":"Anu Shrestha","photoUrl":"","userId":"15243898305987665146"}}},"source":["def merge_liwc_and_remaining_features(path, filename_remaining, filename_liwc):\n","  '''\n","  function to merge LIWC features and all other features. \n","  \n","  path: path to the folder where Generated_features folder is saved\n","  filename_remaining: name of pickle file that contains all other features except LIWC\n","  filename_liwc: name of file that contains LIWC features\n","\n","  '''\n","  # path = '/content/gdrive/My Drive/ECIR 2021 Reproducibility/Data/'\n","  df_remaining_features = pd.read_pickle(os.path.join(path,\"Generated_features/features_for_\"+filename_remaining+\"_noLIWC.pkl\"))\n","  df_liwc = pd.read_csv(os.path.join(path,\"Generated_features/\"+filename_liwc+\".csv\"))\n","\n","  try:\n","    #format liwc dataframe and remove unwanted columns\n","    df_liwc['news_id'] = df_liwc.Filename.apply(lambda x: x.strip('.txt') if x.endswith('.txt') else x)\n","    df_liwc_= df_liwc.drop(columns=['Segment','Filename'])\n","  except:\n","    df_liwc_ = df_liwc.drop(columns=['label'])\n","\n","  #remove duplicate rows if any\n","  df_remaining_features = df_remaining_features.drop_duplicates(subset='news_id', keep='last')\n","\n","  #merge both dfs by news_id\n","  df_merged_features = df_remaining_features.merge(df_liwc_, on='news_id', how='inner')\n","\n","  #assert if merged dataframe have required number of rows and columns\n","  assert df_merged_features.shape[1] == (df_remaining_features.shape[1] + df_liwc_.shape[1]-1)\n","  assert df_merged_features.shape[0] == df_remaining_features.shape[0] == df_liwc_.shape[0]\n","\n","  df_merged_features.to_pickle(os.path.join(path,\"Generated_features/all_features_for_\"+filename_remaining+\".pkl\"))\n","  print(list(df_merged_features.columns))\n","  print(\"Merged and saved all features in file\")\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uv6S61_THlF5","executionInfo":{"status":"ok","timestamp":1604112001811,"user_tz":360,"elapsed":811,"user":{"displayName":"Anu Shrestha","photoUrl":"","userId":"15243898305987665146"}},"outputId":"f7d89100-634d-4978-c2cf-70e2fcd79938","colab":{"base_uri":"https://localhost:8080/"}},"source":["path = '/content/gdrive/My Drive/ECIR 2021 Reproducibility/Data'#replace with your path where Generated_features folder is saved\n","filenames = ['title_politifact','text_politifact','title_buzzfeed','text_buzzfeed','title_gossipcop','text_gossipcop'] #replace with your filenames\n","LIWC_filenames = ['LIWC2015 Results (title_politifact (836 files))','LIWC2015 Results (text_politifact (836 files))',\n","                  'title_buzzfeed_liwc','text_buzzfeed_liwc',\n","                  'LIWC2015 Results (title_gossipcop (19759 files))','LIWC2015 Results (text_gossipcop (19759 files))']#replace with your filenames\n","\n","for filename_remaining, filename_liwc in zip(filenames, LIWC_filenames):\n","  merge_liwc_and_remaining_features(path, filename_remaining, filename_liwc)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["['news_id', 'news_title', 'label', 'smog_index', 'flesch_reading_ease', 'flesch_kincaid_grade_level', 'coleman_liau_index', 'gunning_fog_index', 'ari_index', 'lix_index', 'dale_chall_score', 'dale_chall_known_fraction', 'num_nouns', 'num_propernouns', 'num_personalnouns', 'num_ppssessivenouns', 'num_whpronoun', 'num_determinants', 'num_whdeterminants', 'num_cnum', 'num_adverb', 'num_interjections', 'num_verb', 'num_adj', 'num_vbd', 'num_vbg', 'num_vbn', 'num_vbp', 'num_vbz', 'percentage_stopwords', 'count_uppercased', 'wlen', 'lexical_diversity', 'syllable_count', 'sentence_count', 'Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust', 'Objective', 'compound', 'neg', 'neu', 'pos', 'WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic', 'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they', 'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate', 'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect', 'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend', 'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body', 'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve', 'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture', 'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home', 'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent', 'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC', 'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP']\n","Merged and saved all features in file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AmPA2_tszjGm"},"source":[""],"execution_count":null,"outputs":[]}]}