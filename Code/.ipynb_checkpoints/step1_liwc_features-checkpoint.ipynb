{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BStpLGW4Q2nN"
   },
   "source": [
    "author: \"Anu Shrestha\"\n",
    "\n",
    "This python file contains the code for extracting LIWC features from text.\n",
    "To extract the psychological features we use LIWC tool (2015) from http://liwc.wpengine.com\n",
    "\n",
    "Psychological features can be extracted in two ways:\n",
    "\n",
    "* Either by using the software to compute the features from text\n",
    "* Or by downloading the dictionary provided by the purchased LIWC tool.\n",
    "\n",
    "This file contains the code to extract features using the downloaded dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuiJghs2QU5v"
   },
   "outputs": [],
   "source": [
    "!pip install liwc\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "import liwc\n",
    "\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import *\n",
    "import string\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# In case if the LIWC features are to be computed using dictionary use following code as example to extract required features\n",
    "def tokenize(text):\n",
    "    for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
    "        yield match.group(0)\n",
    "\n",
    "def compute_liwc_from_dict(df, col):\n",
    "  parse, category_names = liwc.load_token_parser('./LIWC2015_English.dic') #path of LIWC dictionary\n",
    "\n",
    "  frames=[]\n",
    "  for text in df[col]:\n",
    "    text_tokens = tokenize(text)\n",
    "    text_counts = Counter(category for token in text_tokens for category in parse(token))\n",
    "\n",
    "    liwc_value_dic = {}\n",
    "    for k,v in text_counts.items():\n",
    "      liwc_value_dic['news_title'] = text\n",
    "      word_count = len([word for word in text.split(' ')])\n",
    "      liwc_value_dic['WC'] = word_count\n",
    "      liwc_value_dic['WPS'] = sum([len(sent.split(' ')) for sent in sent_tokenize(text)])/len(sent_tokenize(text))\n",
    "      liwc_value_dic[k.split(\",\")[0].split(' ')[0]] = (v/word_count)*100\n",
    "    frames.append(pd.DataFrame([liwc_value_dic]))\n",
    "  df_liwc = pd.concat(frames)\n",
    "  return df.merge(df_liwc, on=col)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNS37oTk/QHi0IYo4U5m1Mo",
   "collapsed_sections": [],
   "name": "step1_liwc_features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
