# -*- coding: utf-8 -*-
"""liwc_features.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1msryGE0IgTFn_DyGfCkzgjPu_08zmMXf

# To extract the psycho-linguistic features we use LIWC tool (2015) from http://liwc.wpengine.com

* Either we can use the software to compute psycho-linguistic features from text
* Or we can download the dictionary provided by LIWC and extract features based on that dictionary
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install liwc


import nltk
nltk.download("punkt")
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
stops = stopwords.words('english')
nltk.download('averaged_perceptron_tagger')
from nltk.tag import pos_tag
from nltk.tokenize import RegexpTokenizer
from nltk import sent_tokenize
import re
import liwc

from textblob import TextBlob
import pandas as pd
import numpy as np
from collections import Counter
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.metrics import *
import string
from matplotlib import pyplot as plt
# %matplotlib inline



def format_dataframe(df, title_or_text):
  try:
    df.rename(columns={'A':'news_id','B':'news_title','C':'news_text',
                       'D':'source','E':'news_publish_date','F':'news_top_img',
                       'G':'news_author','H':'label'}, inplace=True)
    df.drop(df.index[0], inplace=True)
    df.label = df.label.apply(lambda x: 1 if x in ["fake","Fake"] else 0)
    new_names = [(i,title_or_text+"_"+i) for i in df.iloc[:, 3:].columns.values]
    df.rename(columns = dict(new_names), inplace=True)
    df[title_or_text+'_wlen'] = df['news_'+title_or_text].apply(average_word_length)
  except:
    pass
  return df


def tokenize(text):
    # you may want to use a smarter tokenizer
    for match in re.finditer(r'\w+', text, re.UNICODE):
        yield match.group(0)

def compute_liwc_from_dict(df, col):
  parse, category_names = liwc.load_token_parser('./LIWC2015_English.dic') #path of LIWC dictionary

  frames=[]
  for text in df[col]:
    print(text)
    text_tokens = tokenize(text)
    print(text_tokens)
    text_counts = Counter(category for token in text_tokens for category in parse(token))
    print(text_counts)

    liwc_value_dic = {}
    for k,v in text_counts.items():
      liwc_value_dic['news_title'] = text
      word_count = len([word for word in text.split(' ')])
      liwc_value_dic['WC'] = word_count
      liwc_value_dic['WPS'] = sum([len(sent.split(' ')) for sent in sent_tokenize(text)])/len(sent_tokenize(text))
      liwc_value_dic[k.split(",")[0].split(' ')[0]] = (v/word_count)*100
    frames.append(pd.DataFrame([liwc_value_dic]))
    break
  df_liwc = pd.concat(frames)
  return df.merge(df_liwc, on=col)